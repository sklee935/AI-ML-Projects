##3. reinforcement_learning/q_learning_gridworld.py
목표: Q-learning 알고리즘을 간단한 GridWorld 환경에서 적용하여 에이전트가 목표 지점에 도달하도록 학습시키는 예제##

import numpy as np
import random

class GridWorld:
    def __init__(self, size=4, start=(0,0), goal=(3,3)):
        self.size = size
        self.start = start
        self.goal = goal
        self.reset()
        
    def reset(self):
        self.agent_pos = self.start
        return self.agent_pos
    
    def step(self, action):
        # 액션: 0=상, 1=우, 2=하, 3=좌
        x, y = self.agent_pos
        if action == 0 and x > 0:
            x -= 1
        elif action == 1 and y < self.size - 1:
            y += 1
        elif action == 2 and x < self.size - 1:
            x += 1
        elif action == 3 and y > 0:
            y -= 1
        self.agent_pos = (x, y)
        reward = 1 if self.agent_pos == self.goal else -0.1
        done = self.agent_pos == self.goal
        return self.agent_pos, reward, done

def q_learning(env, episodes=500, alpha=0.1, gamma=0.9, epsilon=0.1):
    q_table = {}
    for i in range(env.size):
        for j in range(env.size):
            q_table[(i,j)] = [0,0,0,0]  # 4가지 액션에 대한 Q값
    for episode in range(episodes):
        state = env.reset()
        done = False
        while not done:
            if random.uniform(0,1) < epsilon:
                action = random.choice([0,1,2,3])
            else:
                action = np.argmax(q_table[state])
            next_state, reward, done = env.step(action)
            best_next = max(q_table[next_state])
            q_table[state][action] += alpha * (reward + gamma * best_next - q_table[state][action])
            state = next_state
    return q_table

if __name__ == "__main__":
    env = GridWorld()
    q_table = q_learning(env)
    print("Learned Q-table:")
    for state in sorted(q_table.keys()):
        print(state, q_table[state])
